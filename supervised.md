# Supervised Machine Learning

## Teaching Resources

This page contains resources for teaching supervised machine learning, including example notebooks and guides.

- [Linear Regression Example Notebook](https://github.com/neelsoumya/python_machine_learning/files/linear_regression.ipynb)

- [My lecture on the bias variance tradeoff](https://www.youtube.com/watch?v=4_la9-Ehvmo)

- [Excellent explanation of log-likelihood](https://journals.sagepub.com/doi/10.1177/2515245917744314)

- Bias and fairness (recidivism dataset, COMPAS)
  
- Logistic regression log odds plots (can be used to detect bias and fairness)

- [Tutorial on logistic regression](https://github.com/neelsoumya/python_machine_learning/blob/main/logistic_intro_simple.md)

- [Logistic regression](https://github.com/neelsoumya/python_machine_learning/blob/main/logistic_regression_python_simple.ipynb)

- [Practical logistic regression](https://github.com/neelsoumya/python_machine_learning/blob/main/practical_logistic_regression.md)

- PRACTICAL: COMPAS data bias

- Also see binary response logistic regression models (https://cambiotraining.github.io/stats-glm/materials/glm-practical-logistic-binary.html)

- Animation of gradient descent using Vicki and Martin code see email `core_stats_slides-plot v3.qmd`

https://github.com/neelsoumya/python_machine_learning/blob/main/core-stats-slides-plots_v3.qmd

Courtesy Vicki Hodgson and Martin van Rongen

 - https://lindeloev.github.io/tests-as-linear/

- Feature Engineering and Selection for Machine Learning Models in Python. Delivered to the quality of a Level 7 postgraduate audience.  Incorporate the concepts, practical demonstrations, and relevant business insight.

- [Feature selection using linear models](https://github.com/neelsoumya/python_machine_learning/blob/main/feature_engineering_linearmodels.ipynb)

- [Advanced feature selection](https://github.com/neelsoumya/python_machine_learning/blob/main/feature_selection.ipynb)

- [Business cases and projects using feature selection](https://github.com/neelsoumya/python_machine_learning/blob/main/business_cases_feature_engneering.ipynb)

- [LASSO and random forests feature importance](https://github.com/neelsoumya/python_machine_learning/blob/main/feature_selection_LASSO_trees.ipynb)

- [ISLP code on feature selection](https://github.com/intro-stat-learning/ISLP_labs/blob/stable/Ch06-varselect-lab.ipynb)

- [Shiny app to demonstrate feature selection](https://sb2333.shinyapps.io/shiny_feature_selection/)

- Vicki slides to demonstrate logistic regression and gradient descent/maximum likelihood [slides](https://github.com/neelsoumya/basic_statistics/blob/master/2025_bbs-stats_VickyHodgson.pptx)


- Something about feature engineering

[Slides on feature engineering and feature selection](https://github.com/neelsoumya/python_machine_learning/blob/main/talk_featureselection_ML_SoumyaBanerjee.pptx)


- cross validation

- sensitivity and specificity, precision and recall

- AUC, AUPR
-  [ROC curve using scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)

- Logistic regression

- ANNs talk briefly as special case of logistic regression

- Decision trees

- Random forests

- [Machine learning models explained visually](https://mlu-explain.github.io/)

- https://machinelearningmastery.com/10-python-one-liners-every-machine-learning-practitioner-should-know/

- [Artificial neural networks and convolutional neural networks](https://github.com/neelsoumya/teaching_neural_networks)

More resources will be added soon!
